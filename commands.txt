1 Command to run the server
uvicorn main1:app --host 127.0.0.1 --port 5000 --reload

2 How to pass a question to the API
curl -X POST "http://127.0.0.1:5000/api/" -F "question"

3 Prompts
"You are a problem-solving expert. Use the given context if available. Provide a precise and concise answer, not a sentence, just the value. Do not suggest any external applications or softwares. Do the calculations on your own. Do NOT include explanations, code blocks, or additional text. Be straightforward and to the point."
"You are answering graded assignments. Use provided context strictly. Do not assume missing data. Return only the final answer, no explanations."


-------------------------------------------------------
Copilot Code with Python Solver
from fastapi import FastAPI, Form, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os
import httpx
import json
import fitz  # PyMuPDF for PDF text extraction
from typing import Optional

# Get the AIPROXY_TOKEN from environment.
AIPROXY_TOKEN = os.getenv("AIPROXY_TOKEN")
if not AIPROXY_TOKEN:
    raise ValueError("AIPROXY_TOKEN environment variable is not set! Run 'export AIPROXY_TOKEN=your-token' before starting FastAPI.")

# LLM Proxy endpoint.
AIPROXY_BASE_URL = "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions"

app = FastAPI(title="Enhanced TDS Solver API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Response model.
class AnswerResponse(BaseModel):
    answer: str

# System prompt to enforce strict answer formatting.
SYSTEM_PROMPT = (
    "You are a highly accurate data science assignment assistant. "
    "When answering, do not include any extra text or chain-of-thought details. "
    "Return only a JSON object with a single key 'final_answer'. "
    "For example, if the answer is the number 42, output: {\"final_answer\": 42}. "
    "If the answer is text, output: {\"final_answer\": \"Exact answer here\"}."
)

def extract_text_from_pdf(pdf_bytes: bytes) -> str:
    """
    Extracts text from a PDF as a single string.
    Returns only the first 3000 characters.
    """
    try:
        pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
        text = "\n".join(page.get_text("text") for page in pdf_document)
        return text[:3000]
    except Exception as e:
        print("Error extracting text from PDF:", e)
        return ""

def extract_text_from_jsonl(jsonl_bytes: bytes) -> str:
    """
    Extracts text from a JSONL (or JSON) file.
    Returns the first 3000 characters as context.
    """
    try:
        text = jsonl_bytes.decode("utf-8", errors="ignore")
        return text[:3000]
    except Exception as e:
        print("Error extracting text from JSONL:", e)
        return ""

def truncate_text(text: str, max_length: int) -> str:
    """
    Truncates the text if it exceeds max_length characters.
    """
    return text if len(text) <= max_length else text[:max_length] + "..."

def build_enhanced_prompt(question: str, context: str) -> str:
    """
    Builds a prompt that instructs the LLM to think step-by-step and return only
    the final answer in strict JSON format.
    """
    prompt = "Below is the chain-of-thought reasoning (do not include any extra commentary):\n"
    if context:
        prompt += f"Context:\n{context}\n\n"
    prompt += f"Question: {question}\n\n"
    prompt += (
        "Now, think step-by-step through the problem and then provide only your final answer. "
        "IMPORTANT: Return your final answer as a valid JSON object with the key 'final_answer' and nothing else."
    )
    return prompt

def extract_final_answer(response_text: str) -> str:
    """
    Attempts to parse the LLM response as JSON and extract the value for 'final_answer'.
    If JSON parsing fails, returns the stripped version of the response.
    """
    try:
        parsed = json.loads(response_text)
        return str(parsed.get("final_answer", "")).strip()
    except json.JSONDecodeError:
        return response_text.strip()

def get_llm_answer(question: str, context: str = "") -> str:
    """
    Calls the LLM with an enhanced prompt and returns the final answer.
    """
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {AIPROXY_TOKEN}"
    }
    MAX_QUESTION_LENGTH = 2500
    truncated_question = truncate_text(question, MAX_QUESTION_LENGTH)
    truncated_context = truncate_text(context, 3000) if context else ""
    
    prompt = build_enhanced_prompt(truncated_question, truncated_context)
    
    payload = {
        "model": "gpt-4o-mini",  # Modify as needed.
        "temperature": 0,        # Lower temperature for deterministic output.
        "max_tokens": 500,       # Adjust as necessary.
        "messages": [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ],
    }
    
    try:
        response = httpx.post(AIPROXY_BASE_URL, json=payload, headers=headers, timeout=60.0)
        if response.status_code == 200:
            raw_reply = response.json()["choices"][0]["message"]["content"].strip()
            return extract_final_answer(raw_reply)
        elif response.status_code == 429:
            return "AIPROXY monthly request limit reached. Try again next month!"
        elif response.status_code == 403:
            return "AIPROXY cost limit exceeded. Requests are blocked!"
        else:
            return f"AIPROXY Error {response.status_code}: {response.text}"
    except httpx.TimeoutException:
        return "AIPROXY request timed out. Try again later."
    except httpx.RequestError as e:
        return f"Failed to connect to AIPROXY: {str(e)}"

def python_solver(question: str, file_bytes: bytes, filename: str) -> Optional[str]:
    """
    Generalized Python solver for structured data problems.
    
    – If the uploaded file is JSON/JSONL, attempt to parse it into a list of records.
    – Use rudimentary keyword matching on the question (e.g., sum, total, average)
      to decide if an arithmetic operation is appropriate.
    – If, for example, the question asks for a total/sum, try to sum numeric values for
      the field names that best match keywords found in the question.
    
    Returns the computed answer as a string if successful; otherwise, returns None.
    """
    if filename.endswith((".json", ".jsonl")):
        try:
            decoded = file_bytes.decode("utf-8", errors="ignore")
            lines = decoded.splitlines()
            records = []
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                try:
                    record = json.loads(line)
                    records.append(record)
                except Exception as e:
                    print("Error processing line:", line, e)
            if not records:
                return None

            question_lower = question.lower()
            # Look for keywords that indicate an aggregation operation.
            if "sum" in question_lower or "total" in question_lower:
                field_sums = {}
                # Iterate over records and try to accumulate numeric fields.
                for rec in records:
                    for key, value in rec.items():
                        try:
                            num = float(value)
                            field_sums.setdefault(key, 0)
                            field_sums[key] += num
                        except Exception:
                            pass
                if not field_sums:
                    return None
                # Try to choose the field that best matches the question.
                candidate_key = None
                for key in field_sums:
                    if key.lower() in question_lower:
                        candidate_key = key
                        break
                if candidate_key is None:
                    # As a fallback, select the field with the highest total.
                    candidate_key = max(field_sums, key=lambda k: field_sums[k])
                total = field_sums.get(candidate_key)
                # Return as an integer if possible.
                total = int(total) if total is not None and float(total).is_integer() else total
                return str(total)
            # You can add more arithmetic or statistical operations here.
        except Exception as e:
            print("Error in python_solver:", e)
            return None
    return None

@app.post("/api/", response_model=AnswerResponse)
async def solve_question(
    question: str = Form(...),
    file: Optional[UploadFile] = File(None)
):
    """
    Receives an assignment question and an optional file.
    If a structured file is attached, attempts to solve the problem using Python.
    If the Python solver returns a result, that result (which is exactly the final answer)
    is returned. Otherwise, context is extracted and the LLM is queried.
    """
    context = ""
    computed_answer = None

    if file:
        filename = file.filename.lower()
        try:
            file_bytes = await file.read()
            # Try the Python solver for structured data (without hardcoding for a specific question)
            computed_answer = python_solver(question, file_bytes, filename)
            # Also, for file types that are not structured for computation, extract text.
            if computed_answer is None:
                if filename.endswith(".pdf") or file.content_type == "application/pdf":
                    context = extract_text_from_pdf(file_bytes)
                elif filename.endswith((".jsonl", ".json")):
                    context = extract_text_from_jsonl(file_bytes)
                else:
                    context = file_bytes.decode("utf-8", errors="ignore")[:3000]
        except Exception as e:
            print(f"Error reading file {file.filename}: {str(e)}")

    if computed_answer is not None:
        final_answer = computed_answer
    else:
        final_answer = get_llm_answer(question, context)
    
    # Return exactly the final answer.
    return AnswerResponse(answer=final_answer)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=5000, reload=True)